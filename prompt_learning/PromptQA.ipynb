{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to set up our environment.\n",
    "\n",
    "This Jupyter Notebook needs the following packages installed:\n",
    "- [PyTorch](https://pytorch.org/get-started/locally/)\n",
    "- [transformers](https://huggingface.co/docs/transformers/installation)\n",
    "- [datasets](https://huggingface.co/docs/datasets/installation)\n",
    "- [opendelta](https://opendelta.readthedocs.io/en/latest/notes/installation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TRANSFORMERS_CACHE=/Users/rongwang/Desktop/DL project/path/to/cache\n",
      "env: HF_MODULES_CACHE=/Users/rongwang/Desktop/DL project/path/to/cache\n",
      "env: HF_DATASETS_CACHE=/Users/rongwang/Desktop/DL project/path/to/cache\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set cache directory if desired\n",
    "# if you do not set a cache directory then default values are used (usually '~/.cache')\n",
    "import os\n",
    "CACHE_DIR=os.path.abspath(os.path.expanduser('path/to/cache')) # I donot understand this line\n",
    "%set_env TRANSFORMERS_CACHE $CACHE_DIR\n",
    "%set_env HF_MODULES_CACHE $CACHE_DIR\n",
    "%set_env HF_DATASETS_CACHE $CACHE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from datasets import load_dataset, load_metric, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    DefaultDataCollator,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    DistilBertForQuestionAnswering,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EvalPrediction,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the SQuAD dataset which is an english extractive QA dataset for the RC task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'context', 'question', 'answers'],\n",
      "    num_rows: 87599\n",
      "})\n",
      "Dataset({\n",
      "    features: ['context', 'question', 'answers', 'id'],\n",
      "    num_rows: 100\n",
      "})\n",
      "Dataset({\n",
      "    features: ['context', 'question', 'answers', 'id'],\n",
      "    num_rows: 100\n",
      "})\n",
      "Dataset({\n",
      "    features: ['context', 'question', 'id'],\n",
      "    num_rows: 177\n",
      "})\n",
      "Dataset({\n",
      "    features: ['context', 'question', 'id'],\n",
      "    num_rows: 1126\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "# load dataset\n",
    "\n",
    "import json\n",
    "import os\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "# The datasets library is a library for loading and preprocessing datasets for machine learning. The Dataset class is a way to handle large datasets in a way that is memory efficient.\n",
    "    \n",
    "\n",
    "\n",
    "def read_data(filepath: str):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return Dataset.from_list(list(json.load(f).values()))\n",
    "\n",
    "\n",
    "filepath_1 = os.path.abspath('rc_traindev/squad_train.json')\n",
    "filepath_2 = os.path.abspath('rc_traindev/squad_dev.json')\n",
    "filepath_3 = os.path.abspath('rc_traindev/rc_train.json')\n",
    "filepath_4 = os.path.abspath('rc_traindev/rc_dev.json')\n",
    "\n",
    "filepath_5 = os.path.abspath('rc_traindev/rc_test_1.json')\n",
    "filepath_6 = os.path.abspath('rc_traindev/rc_test_2.json')\n",
    "\n",
    "squad_train = read_data(filepath_1)\n",
    "squad_dev = read_data(filepath_2)\n",
    "rc_train = read_data(filepath_3)\n",
    "rc_dev = read_data(filepath_4)\n",
    "rc_test = read_data(filepath_5)\n",
    "rc_final = read_data(filepath_6)\n",
    "\n",
    "print(squad_train)\n",
    "print(rc_train)\n",
    "print(rc_dev)\n",
    "print(rc_test)\n",
    "print(rc_final)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predicted_answers_robertalarge_2.json', 'w') as f:\n",
    "        json.dump(predictions, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will preprocess the dataset (training and evaluation data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8857d6d1dddf472db3c1e267d17eceb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1528973bde46a2ae65ec1ea7739439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc3474dc6394b3a91eb524669caf37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7d42a508604fdd9ab3650faca0ce68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# preprocess data\n",
    "\n",
    "max_length = 500\n",
    "stride = 128\n",
    "model_checkpoint =\"deepset/roberta-large-squad2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "tokenized_squad_train = preprocess_dataset(squad_train, tokenizer)\n",
    "\n",
    "tokenized_squad_dev = preprocess_dataset(squad_dev, tokenizer)\n",
    "\n",
    "tokenized_rc_train = preprocess_dataset(rc_train, tokenizer)\n",
    "tokenized_rc_dev = preprocess_dataset(rc_dev, tokenizer)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RC is often evaluated in terms of F1 on the answer word level.\n",
    "Therefore we use the predictions to extract answers which will be compared with the gold answers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we set up the model.\n",
    "\n",
    "Note that you have to re-run this cell if you want to start from scratch (i.e. using the pre-trained weights). Don't forget to re-initalize your trainer as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilbert-base-cased-distilled-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "#model =  DistilBertForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "model =  AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "model= accelerator.prepare(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the [transformers](https://huggingface.co/docs/transformers)' [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Trainer).\n",
    "You can modify training using [TrainingArguments](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up training\n",
    "# you might want to adapt the hyperparameters so that in runs in feasible time on your machine\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models\",\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=32,\n",
    "    num_train_epochs=5,  # max_steps will override this value\n",
    "    # max_steps=1000,  # comment out if this is not wanted\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    label_names=[\"start_positions\", \"end_positions\"]\n",
    ")\n",
    "\n",
    "# data collator for batching\n",
    "data_collator = DefaultDataCollator()\n",
    "\n",
    "# the actual trainer which performs training and evaluation\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_rc_train,\n",
    "    eval_dataset=tokenized_rc_dev,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=get_evaluate_fn(\n",
    "        rc_dev,\n",
    "        tokenized_rc_dev[\"context_span\"],\n",
    "        tokenized_rc_dev[\"offset_mapping\"],\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab76806c0e540589dbc002e3da0bf67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.784677028656006,\n",
       " 'eval_exact_match': 16.0,\n",
       " 'eval_f1': 18.25,\n",
       " 'eval_runtime': 22.4068,\n",
       " 'eval_samples_per_second': 4.463,\n",
       " 'eval_steps_per_second': 0.179}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do an initial evaluation\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the result for #model =  DistilBertForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "\n",
    "{'eval_loss': 4.679508686065674, 'eval_exact_match': 24.0, 'eval_f1': 28.49171071176885, 'eval_runtime': 20.2195, 'eval_samples_per_second': 4.946, 'eval_steps_per_second': 0.198, 'epoch': 1.0}\n",
    "{'eval_loss': 4.362856388092041, 'eval_exact_match': 19.0, 'eval_f1': 24.63933564422695, 'eval_runtime': 20.8955, 'eval_samples_per_second': 4.786, 'eval_steps_per_second': 0.191, 'epoch': 2.0}\n",
    "{'eval_loss': 4.197320461273193, 'eval_exact_match': 19.0, 'eval_f1': 24.13933564422695, 'eval_runtime': 20.2452, 'eval_samples_per_second': 4.939, 'eval_steps_per_second': 0.198, 'epoch': 3.0}\n",
    "{'train_runtime': 278.9048, 'train_samples_per_second': 1.076, 'train_steps_per_second': 0.011, 'train_loss': 0.6186825037002563, 'epoch': 3.0}\n",
    "TrainOutput(global_step=3, training_loss=0.6186825037002563, metrics={'train_runtime': 278.9048, 'train_samples_per_second': 1.076, 'train_steps_per_second': 0.011, 'train_loss': 0.6186825037002563, 'epoch': 3.0})\n",
    "\n",
    "the result for #model =  AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "{'eval_loss': 4.582829475402832, 'eval_exact_match': 23.0, 'eval_f1': 27.79257651263465, 'eval_runtime': 20.6068, 'eval_samples_per_second': 4.853, 'eval_steps_per_second': 0.194, 'epoch': 1.0}\n",
    "{'eval_loss': 4.212737560272217, 'eval_exact_match': 21.0, 'eval_f1': 24.745396250287556, 'eval_runtime': 20.2435, 'eval_samples_per_second': 4.94, 'eval_steps_per_second': 0.198, 'epoch': 2.0}\n",
    "{'eval_loss': 4.005221843719482, 'eval_exact_match': 18.0, 'eval_f1': 21.14583333333333, 'eval_runtime': 27.3378, 'eval_samples_per_second': 3.658, 'eval_steps_per_second': 0.146, 'epoch': 3.0}\n",
    "{'eval_loss': 3.9222028255462646, 'eval_exact_match': 15.0, 'eval_f1': 17.233333333333334, 'eval_runtime': 19.6553, 'eval_samples_per_second': 5.088, 'eval_steps_per_second': 0.204, 'epoch': 4.0}\n",
    "{'eval_loss': 3.880044460296631, 'eval_exact_match': 15.0, 'eval_f1': 17.233333333333334, 'eval_runtime': 22.1952, 'eval_samples_per_second': 4.505, 'eval_steps_per_second': 0.18, 'epoch': 5.0}\n",
    "{'train_runtime': 492.1944, 'train_samples_per_second': 1.016, 'train_steps_per_second': 0.01, 'train_loss': 0.4992131233215332, 'epoch': 5.0}\n",
    "TrainOutput(global_step=5, training_loss=0.4992131233215332, metrics={'train_runtime': 492.1944, 'train_samples_per_second': 1.016, 'train_steps_per_second': 0.01, 'train_loss': 0.4992131233215332, 'epoch': 5.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rongwang/miniconda3/envs/mps/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd99451c87642a3861c97484cee2bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8164e38423451f981296783a09fef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.582829475402832, 'eval_exact_match': 23.0, 'eval_f1': 27.79257651263465, 'eval_runtime': 20.6068, 'eval_samples_per_second': 4.853, 'eval_steps_per_second': 0.194, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb77fdc74664db28b6ce404939016f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.212737560272217, 'eval_exact_match': 21.0, 'eval_f1': 24.745396250287556, 'eval_runtime': 20.2435, 'eval_samples_per_second': 4.94, 'eval_steps_per_second': 0.198, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7869d1d92a954e458fce82e8fec9c8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.005221843719482, 'eval_exact_match': 18.0, 'eval_f1': 21.14583333333333, 'eval_runtime': 27.3378, 'eval_samples_per_second': 3.658, 'eval_steps_per_second': 0.146, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a19c7e21bd3446e9dac25ec85186ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.9222028255462646, 'eval_exact_match': 15.0, 'eval_f1': 17.233333333333334, 'eval_runtime': 19.6553, 'eval_samples_per_second': 5.088, 'eval_steps_per_second': 0.204, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "082d7d35f4b94189994f6410e9b9200a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.880044460296631, 'eval_exact_match': 15.0, 'eval_f1': 17.233333333333334, 'eval_runtime': 22.1952, 'eval_samples_per_second': 4.505, 'eval_steps_per_second': 0.18, 'epoch': 5.0}\n",
      "{'train_runtime': 492.1944, 'train_samples_per_second': 1.016, 'train_steps_per_second': 0.01, 'train_loss': 0.4992131233215332, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5, training_loss=0.4992131233215332, metrics={'train_runtime': 492.1944, 'train_samples_per_second': 1.016, 'train_steps_per_second': 0.01, 'train_loss': 0.4992131233215332, 'epoch': 5.0})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform training\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   The Trainer class automatically saves the model after training. The model is saved in the directory specified by the output_dir argument in TrainingArguments. You can load the trained model using the from_pretrained method of the model class, like this:\n",
    "model = ModelClass.from_pretrained(\"./models\")\n",
    "Replace ModelClass with the actual class of your model. For example, if you're using a BERT model, you would use BertForQuestionAnswering.from_pretrained.\n",
    "\n",
    "Once you've loaded the trained model, you can use it to make predictions on your new test dataset. You can do this by calling the predict method of the Trainer class, like this:\n",
    "\n",
    "\n",
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'context', 'question', 'answers'],\n",
      "    num_rows: 87599\n",
      "})\n",
      "Dataset({\n",
      "    features: ['context', 'question', 'answers', 'id'],\n",
      "    num_rows: 100\n",
      "})\n",
      "Dataset({\n",
      "    features: ['context', 'question', 'id'],\n",
      "    num_rows: 177\n",
      "})\n",
      "{'id': '5733be284776f41900661182', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'answers': {'answer_start': [515], 'text': ['Saint Bernadette Soubirous']}}\n",
      "Dataset({\n",
      "    features: ['context', 'question', 'id'],\n",
      "    num_rows: 177\n",
      "})\n",
      "{'context': 'Humans did not reach space until the second half of the 20th century. They needed somehow to break past Earths gravity. A rocket moves rapidly in one direction. The device is propelled by particles flying out of it at high speed in the other direction. There are records of the Chinese using rockets in war against the Mongols as early as the 13th century. The Mongols then used rockets to attack Eastern Europe. Early rockets were also used to launch fireworks.  Rockets were used for centuries before anyone could explain how they worked. The theory came about in 1687. Isaac Newton (16431727) described three basic laws of motion, now referred to as Newtons Laws of Motion: 1. An object in motion will remain in motion unless acted upon by a force. 2. Force equals mass multiplied by acceleration. 3. To every action, there is an equal and opposite reaction. Which of these three best explains how a rocket works? Newtons third law of motion. When a rockets propulsion pushes in one direction, the rocket moves in the opposite direction, as seen in the Figure 23.12. For a long time, many people believed that a rocket wouldnt work in space. There would be nothing for the rocket to push against. But they do work! Fuel is ignited in a chamber. The gases in the chamber explode. The explosion creates pressure that forces the gases out of one side of the rocket. The rocket moves in the opposite direction, as shown in Figure 23.13. The force pushing the rocket is called thrust.  For centuries, rockets were powered by gunpowder or other solid fuels. These rockets could travel only short distances. Around the turn of the 20th century, several breakthroughs took place. These breakthroughs led to rockets that could travel beyond Earth. Liquid fuel gave rockets enough power to escape Earths gravity (Figure 23.14). By using multiple stages, empty fuel containers could drop away. This reduced the mass of the rocket so that it could fly higher. Rockets were used during World War II. The V2 was the first human-made object to travel high enough to be considered in space (Figure 23.15). Its altitude was 176 km (109 miles) above Earths surface. Wernher von Braun was a German rocket scientist. After he fled Germany in WWII, he helped the United States develop missile weapons. After the war, von Braun worked for NASA. He designed the Saturn V rocket (Figure  One of the first uses of rockets in space was to launch satellites. A satellite is an object that orbits a larger object. An orbit is a circular or elliptical path around an object. Natural objects in orbit are called natural satellites. The Moon is a natural satellite. Human-made objects in orbit are called artificial satellites. There are more and more artificial satellites orbiting Earth all the time. They all get into space using some sort of rocket.  Why do satellites stay in orbit? Why dont they crash into Earth due to the planets gravity? Newtons law of universal gravitation describes what happens. Every object in the universe is attracted to every other object. Gravity makes an apple fall to the ground. Gravity also keeps you from floating away into the sky. Gravity holds the Moon in orbit around Earth. It keeps Earth in orbit around the Sun. Newton used an example to explain how gravity makes orbiting possible. Imagine a cannonball launched from a high mountain, as shown in Figure 23.17. If the cannonball is launched at a slow speed, it will fall back to Earth. This is shown as paths (A) and (B). Something different happens if the cannonball is launched at a fast speed. The Earth below curves away at the same rate that the cannonball falls. The cannonball then goes into a circular orbit, as in path (C). If the cannonball is launched even faster, it could go into an elliptical orbit (D). It might even leave Earths gravity and go into space (E). Unfortunately, Newtons idea would not work in real life. A cannonball launched at a fast speed from Mt. Everest would not go into orbit.', 'question': 'U.S. agency in charge of space exploration', 'id': '0'}\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "# load dataset\n",
    "# import packages\n",
    "from datasets import load_dataset, load_metric, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    DefaultDataCollator,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    DistilBertForQuestionAnswering,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EvalPrediction,\n",
    ")\n",
    "    \n",
    "import json\n",
    "import os\n",
    "from datasets import Dataset\n",
    "from accelerate import Accelerator\n",
    "\n",
    "# The datasets library is a library for loading and preprocessing datasets for machine learning. The Dataset class is a way to handle large datasets in a way that is memory efficient.\n",
    "    \n",
    "\n",
    "\n",
    "def read_data(filepath: str):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return Dataset.from_list(list(json.load(f).values()))\n",
    "\n",
    "\n",
    "filepath_1 = os.path.abspath('rc_traindev/squad_train.json')\n",
    "filepath_2 = os.path.abspath('rc_traindev/squad_dev.json')\n",
    "filepath_3 = os.path.abspath('rc_traindev/rc_train.json')\n",
    "filepath_4 = os.path.abspath('rc_traindev/rc_dev.json')\n",
    "\n",
    "filepath_5 = os.path.abspath('rc_traindev/rc_test_1.json')\n",
    "\n",
    "squad_train = read_data(filepath_1)\n",
    "squad_dev = read_data(filepath_2)\n",
    "rc_train = read_data(filepath_3)\n",
    "rc_dev = read_data(filepath_4)\n",
    "rc_test = read_data(filepath_5)\n",
    "\n",
    "print(squad_train)\n",
    "print(rc_train)\n",
    "print(rc_test)\n",
    "print(squad_train[0])\n",
    "print(rc_test)\n",
    "print(rc_test[0])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384\n",
    "stride = 128\n",
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_validation_dataset\u001b[39m(dataset: Dataset, tokenizer, max_length: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m400\u001b[39m, stride: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m128\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_function\u001b[39m(examples, tokenizer, max_length):\n\u001b[1;32m      5\u001b[0m         questions \u001b[39m=\u001b[39m [q\u001b[39m.\u001b[39mstrip() \u001b[39mfor\u001b[39;00m q \u001b[39min\u001b[39;00m examples[\u001b[39m\"\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m\"\u001b[39m]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "def preprocess_validation_dataset(dataset: Dataset, tokenizer, max_length: int = 400, stride: int = 128):\n",
    "    \n",
    "\n",
    "    def preprocess_function(examples, tokenizer, max_length):\n",
    "        questions = [q.strip() for q in examples[\"question\"]]\n",
    "        inputs = tokenizer(\n",
    "            questions,\n",
    "            examples[\"context\"],\n",
    "            max_length=max_length,\n",
    "            truncation=\"only_second\",\n",
    "            stride=stride,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "\n",
    "        # Create a map from overflowing tokens to the original sample they came from\n",
    "        sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "        inputs[\"example_id\"] = [examples[\"id\"][i] for i in sample_map]\n",
    "\n",
    "        # Modify the offset mapping to only keep offsets for the context\n",
    "        for i in range(len(inputs[\"input_ids\"])):\n",
    "            sequence_ids = inputs.sequence_ids(i)\n",
    "            offset = inputs[\"offset_mapping\"][i]\n",
    "            inputs[\"offset_mapping\"][i] = [\n",
    "                o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "            ]\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    return dataset.map(\n",
    "        preprocess_function,\n",
    "        fn_kwargs=dict(tokenizer=tokenizer, max_length=max_length),\n",
    "        batched=True,\n",
    "        remove_columns=dataset.column_names,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d7842a3ac14b929760a8767aeaf6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/177 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(177, 551)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "model_checkpoint = \"huggingface-course/bert-finetuned-squad\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "validation_dataset = rc_test.map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=rc_test.column_names,\n",
    ")\n",
    "len(rc_test), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 158, 119, 156, 119, 4792, 1107, 2965, 1104, 2000, 10016, 102, 22143, 1225, 1136, 2519, 2000, 1235, 1103, 1248, 1544, 1104, 1103, 3116, 1432, 119, 1220, 1834, 5006, 1106, 2549, 1763, 2746, 1116, 9926, 119, 138, 8964, 5279, 5223, 1107, 1141, 2447, 119, 1109, 4442, 1110, 17314, 1118, 9150, 3754, 1149, 1104, 1122, 1120, 1344, 2420, 1107, 1103, 1168, 2447, 119, 1247, 1132, 3002, 1104, 1103, 1922, 1606, 18437, 1107, 1594, 1222, 1103, 24640, 1112, 1346, 1112, 1103, 5435, 1432, 119, 1109, 24640, 1173, 1215, 18437, 1106, 2035, 2882, 1980, 119, 4503, 18437, 1127, 1145, 1215, 1106, 4286, 19612, 119, 24249, 1127, 1215, 1111, 3944, 1196, 2256, 1180, 4137, 1293, 1152, 1589, 119, 1109, 2749, 1338, 1164, 1107, 18030, 1559, 119, 7026, 8102, 113, 19290, 22639, 1559, 24458, 114, 1758, 1210, 3501, 3892, 1104, 4018, 117, 1208, 2752, 1106, 1112, 8102, 1116, 12077, 1104, 12153, 131, 122, 119, 1760, 4231, 1107, 4018, 1209, 3118, 1107, 4018, 4895, 5376, 1852, 1118, 170, 2049, 119, 123, 119, 2300, 22455, 3367, 4321, 18148, 1118, 18383, 119, 124, 119, 1706, 1451, 2168, 117, 1175, 1110, 1126, 4463, 1105, 3714, 3943, 119, 5979, 1104, 1292, 1210, 1436, 7155, 1293, 170, 8964, 1759, 136, 8102, 1116, 1503, 1644, 1104, 4018, 119, 1332, 170, 18437, 21184, 14505, 1107, 1141, 2447, 117, 1103, 8964, 5279, 1107, 1103, 3714, 2447, 117, 1112, 1562, 1107, 1103, 15982, 1695, 119, 1367, 119, 1370, 170, 1263, 1159, 117, 1242, 1234, 2475, 1115, 170, 8964, 2010, 1204, 1250, 1107, 2000, 119, 1247, 1156, 1129, 1720, 1111, 1103, 8964, 1106, 4684, 1222, 119, 1252, 1152, 1202, 1250, 106, 18935, 1110, 25092, 1107, 170, 5383, 119, 1109, 17202, 1107, 1103, 5383, 16099, 119, 1109, 7552, 8743, 2997, 1115, 2088, 1103, 17202, 1149, 1104, 1141, 1334, 1104, 1103, 8964, 119, 1109, 8964, 5279, 1107, 1103, 3714, 2447, 117, 1112, 2602, 1107, 15982, 1695, 119, 1492, 119, 1109, 2049, 5859, 1103, 8964, 1110, 1270, 7113, 119, 1370, 3944, 117, 18437, 1127, 5605, 1118, 2560, 24272, 1137, 1168, 4600, 23769, 119, 1636, 18437, 1180, 3201, 1178, 1603, 12424, 119, 5596, 1103, 1885, 1104, 1103, 3116, 1432, 117, 1317, 15036, 1116, 1261, 1282, 119, 1636, 15036, 1116, 1521, 1106, 18437, 1115, 1180, 3201, 2894, 2746, 119, 5255, 24235, 4251, 1522, 18437, 1536, 1540, 1106, 3359, 2746, 1116, 9926, 113, 15982, 1695, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [None, None, None, None, None, None, None, None, None, None, None, None, [0, 6], [7, 10], [11, 14], [15, 20], [21, 26], [27, 32], [33, 36], [37, 43], [44, 48], [49, 51], [52, 55], [56, 60], [61, 68], [68, 69], [70, 74], [75, 81], [82, 89], [90, 92], [93, 98], [99, 103], [104, 109], [109, 110], [111, 118], [118, 119], [120, 121], [122, 128], [129, 134], [135, 142], [143, 145], [146, 149], [150, 159], [159, 160], [161, 164], [165, 171], [172, 174], [175, 184], [185, 187], [188, 197], [198, 204], [205, 208], [209, 211], [212, 214], [215, 217], [218, 222], [223, 228], [229, 231], [232, 235], [236, 241], [242, 251], [251, 252], [253, 258], [259, 262], [263, 270], [271, 273], [274, 277], [278, 285], [286, 291], [292, 299], [300, 302], [303, 306], [307, 314], [315, 318], [319, 326], [327, 329], [330, 335], [336, 338], [339, 342], [343, 347], [348, 355], [355, 356], [357, 360], [361, 368], [369, 373], [374, 378], [379, 386], [387, 389], [390, 396], [397, 404], [405, 411], [411, 412], [413, 418], [419, 426], [427, 431], [432, 436], [437, 441], [442, 444], [445, 451], [452, 461], [461, 462], [464, 471], [472, 476], [477, 481], [482, 485], [486, 495], [496, 502], [503, 509], [510, 515], [516, 523], [524, 527], [528, 532], [533, 539], [539, 540], [541, 544], [545, 551], [552, 556], [557, 562], [563, 565], [566, 569], [569, 570], [570, 571], [572, 577], [578, 584], [585, 586], [586, 589], [589, 591], [591, 592], [592, 594], [594, 595], [596, 605], [606, 611], [612, 617], [618, 622], [623, 625], [626, 632], [632, 633], [634, 637], [638, 646], [647, 649], [650, 652], [653, 659], [659, 660], [661, 665], [666, 668], [669, 675], [675, 676], [677, 678], [678, 679], [680, 682], [683, 689], [690, 692], [693, 699], [700, 704], [705, 711], [712, 714], [715, 721], [722, 728], [729, 734], [735, 739], [740, 742], [743, 744], [745, 750], [750, 751], [752, 753], [753, 754], [755, 760], [761, 767], [768, 772], [773, 778], [778, 783], [784, 786], [787, 799], [799, 800], [801, 802], [802, 803], [804, 806], [807, 812], [813, 819], [819, 820], [821, 826], [827, 829], [830, 832], [833, 838], [839, 842], [843, 851], [852, 860], [860, 861], [862, 867], [868, 870], [871, 876], [877, 882], [883, 887], [888, 896], [897, 900], [901, 902], [903, 909], [910, 915], [915, 916], [917, 923], [923, 924], [925, 930], [931, 934], [935, 937], [938, 944], [944, 945], [946, 950], [951, 952], [953, 960], [961, 971], [972, 978], [979, 981], [982, 985], [986, 995], [995, 996], [997, 1000], [1001, 1007], [1008, 1013], [1014, 1016], [1017, 1020], [1021, 1029], [1030, 1039], [1039, 1040], [1041, 1043], [1044, 1048], [1049, 1051], [1052, 1055], [1056, 1062], [1063, 1065], [1065, 1066], [1066, 1068], [1068, 1069], [1070, 1073], [1074, 1075], [1076, 1080], [1081, 1085], [1085, 1086], [1087, 1091], [1092, 1098], [1099, 1107], [1108, 1112], [1113, 1114], [1115, 1121], [1122, 1128], [1128, 1129], [1130, 1134], [1135, 1137], [1138, 1143], [1143, 1144], [1145, 1150], [1151, 1156], [1157, 1159], [1160, 1167], [1168, 1171], [1172, 1175], [1176, 1182], [1183, 1185], [1186, 1190], [1191, 1198], [1198, 1199], [1200, 1203], [1204, 1208], [1209, 1211], [1212, 1216], [1216, 1217], [1218, 1222], [1223, 1225], [1226, 1233], [1234, 1236], [1237, 1238], [1239, 1246], [1246, 1247], [1248, 1251], [1252, 1257], [1258, 1260], [1261, 1264], [1265, 1272], [1273, 1280], [1280, 1281], [1282, 1285], [1286, 1295], [1296, 1303], [1304, 1312], [1313, 1317], [1318, 1324], [1325, 1328], [1329, 1334], [1335, 1338], [1339, 1341], [1342, 1345], [1346, 1350], [1351, 1353], [1354, 1357], [1358, 1364], [1364, 1365], [1366, 1369], [1370, 1376], [1377, 1382], [1383, 1385], [1386, 1389], [1390, 1398], [1399, 1408], [1408, 1409], [1410, 1412], [1413, 1418], [1419, 1421], [1422, 1428], [1429, 1431], [1431, 1432], [1432, 1434], [1434, 1435], [1436, 1439], [1440, 1445], [1446, 1453], [1454, 1457], [1458, 1464], [1465, 1467], [1468, 1474], [1475, 1481], [1481, 1482], [1484, 1487], [1488, 1497], [1497, 1498], [1499, 1506], [1507, 1511], [1512, 1519], [1520, 1522], [1523, 1526], [1526, 1532], [1533, 1535], [1536, 1541], [1542, 1547], [1548, 1553], [1553, 1554], [1555, 1560], [1561, 1568], [1569, 1574], [1575, 1581], [1582, 1586], [1587, 1592], [1593, 1602], [1602, 1603], [1604, 1610], [1611, 1614], [1615, 1619], [1620, 1622], [1623, 1626], [1627, 1631], [1632, 1639], [1639, 1640], [1641, 1648], [1649, 1661], [1661, 1662], [1663, 1667], [1668, 1673], [1673, 1674], [1675, 1680], [1681, 1693], [1693, 1694], [1695, 1698], [1699, 1701], [1702, 1709], [1710, 1714], [1715, 1720], [1721, 1727], [1728, 1734], [1735, 1740], [1740, 1741], [1742, 1744], [1744, 1748], [1749, 1753], [1754, 1758], [1759, 1766], [1767, 1773], [1774, 1779], [1780, 1782], [1783, 1789], [1790, 1795], [1795, 1796], [1797, 1804], [1805, 1806], [1806, 1812], [1813, 1815], None], 'example_id': '0'}\n"
     ]
    }
   ],
   "source": [
    "#tokenized_rc_dev = preprocess_dataset(rc_dev, tokenizer)\n",
    "\n",
    "\n",
    "sample = validation_dataset[0]  # Get the first sample from the validation set\n",
    "\n",
    "# Print the result\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74203b7676d646feb8576410d1ceaa46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/177 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "small_eval_set = rc_test\n",
    "trained_checkpoint = \"huggingface-course/bert-finetuned-squad\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)\n",
    "\n",
    "eval_set =  small_eval_set.map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=rc_test.column_names,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ce376cf6d44c29bc8e1e4598503fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd77dee0dc248e3bab6bf4f61e97785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c143572258436f81e5da889d976e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8670d263af5345b7bda7f39843083fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "eval_set_for_model = eval_set.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "eval_set_for_model.set_format(\"torch\")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "batch = {k: eval_set_for_model[k].to(device) for k in eval_set_for_model.column_names}\n",
    "\n",
    "trained_model = AutoModelForQuestionAnswering.from_pretrained(trained_checkpoint).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = trained_model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits = outputs.start_logits.cpu().numpy()\n",
    "end_logits = outputs.end_logits.cpu().numpy()\n",
    "\n",
    "import collections\n",
    "\n",
    "example_to_features = collections.defaultdict(list)\n",
    "for idx, feature in enumerate(validation_dataset):\n",
    "    example_to_features[feature[\"example_id\"]].append(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_set_for_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m max_answer_length \u001b[39m=\u001b[39m \u001b[39m30\u001b[39m\n\u001b[1;32m      5\u001b[0m predicted \u001b[39m=\u001b[39m {}\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfor\u001b[39;00m example \u001b[39min\u001b[39;00m eval_set_for_model:\n\u001b[1;32m      8\u001b[0m     example_id \u001b[39m=\u001b[39m example[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      9\u001b[0m     context \u001b[39m=\u001b[39m example[\u001b[39m\"\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_set_for_model' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_best = 20\n",
    "max_answer_length = 30\n",
    "predicted = {}\n",
    "\n",
    "for example in eval_set_for_model:\n",
    "    example_id = example[\"id\"]\n",
    "    context = example[\"context\"]\n",
    "    answers = []\n",
    "\n",
    "    for feature_index in example_to_features[example_id]:\n",
    "        start_logit = start_logits[feature_index]\n",
    "        end_logit = end_logits[feature_index]\n",
    "        offsets = eval_set[\"offset_mapping\"][feature_index]\n",
    "\n",
    "        start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "        end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "        for start_index in start_indexes:\n",
    "            for end_index in end_indexes:\n",
    "                # Skip answers that are not fully in the context\n",
    "                if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                    continue\n",
    "                # Skip answers with a length that is either < 0 or > max_answer_length.\n",
    "                if (\n",
    "                    end_index < start_index\n",
    "                    or end_index - start_index + 1 > max_answer_length\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                answers.append(\n",
    "                    {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "    predicted[example_id] = { \"answers\": {\"text\": [best_answer[\"text\"]]}, \"id\": example_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    " with open('predicted_answers_3.json', 'w') as f:\n",
    "        json.dump(predicted, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### compare the result with baseline without any fine-tnuning. for rc_test data samples, improve 6% when fine-tuning on rc_train and rc_dev, but not trying on squad_traiin, squad_dev, because of computaional expense on M1 GPU ######\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"deepset/roberta-large-squad2\"\n",
    "question_answerer = pipeline(\"question-answering\", model=model_checkpoint)\n",
    "\n",
    "test_data = rc_test  # Your test dataset\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "# Make predictions for each context-question pair in the test data\n",
    "for i, sample in enumerate(test_data):\n",
    "    context = sample[\"context\"]\n",
    "    question = sample[\"question\"]\n",
    "    answer = question_answerer(question=question, context=context)\n",
    "    \n",
    "    prediction = {\n",
    "        \"answers\": {\"text\": [answer[\"answer\"]]},\n",
    "        \"id\": str(i)\n",
    "    }\n",
    "    \n",
    "    predictions[str(i)] = prediction\n",
    "\n",
    "with open('predicted_answers_robertalarge_test.json', 'w') as f:\n",
    "        json.dump(predictions, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "781ef2da3e9d983ee82cdc5eb270354f9ddafae9147a3214ae59f008783fff8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
